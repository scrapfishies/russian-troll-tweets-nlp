{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts on building a rec system to find users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:42:06.190896Z",
     "start_time": "2020-11-07T00:42:03.625399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pickle \n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# spacy\n",
    "import spacy\n",
    "\n",
    "from preprocessing_funcs import clean_tweet, get_hashtags, get_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:42:07.626453Z",
     "start_time": "2020-11-07T00:42:07.492257Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data_files/processed_tweets.pickle', 'rb') as read_file:\n",
    "    df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:42:07.686112Z",
     "start_time": "2020-11-07T00:42:07.676231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islam kill try say terrorist attack europe ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump apologize attack little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>well president past retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>guess religion christmas aftermath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence lawyer decide official email public can see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                           processed  \n",
       "0  islam kill try say terrorist attack europe ref...  \n",
       "1              clinton trump apologize attack little  \n",
       "2                        well president past retweet  \n",
       "3                 guess religion christmas aftermath  \n",
       "4  pence lawyer decide official email public can see  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:42:10.527580Z",
     "start_time": "2020-11-07T00:42:09.445312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_key</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>source</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>posted</th>\n",
       "      <th>mentions</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.868981e+09</td>\n",
       "      <td>ryanmaxwell_1</td>\n",
       "      <td>1.458672e+12</td>\n",
       "      <td>2016-03-22 18:31:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>7.123460e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"IslamKills\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.571870e+09</td>\n",
       "      <td>detroitdailynew</td>\n",
       "      <td>1.476133e+12</td>\n",
       "      <td>2016-10-10 20:57:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>7.855849e+17</td>\n",
       "      <td>&lt;a href=\"http://twitterfeed.com\" rel=\"nofollow...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"http://detne.ws/2e172jF\"]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.710805e+09</td>\n",
       "      <td>cookncooks</td>\n",
       "      <td>1.487767e+12</td>\n",
       "      <td>2017-02-22 12:43:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>8.343832e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id         user_key    created_at          created_str  \\\n",
       "0  1.868981e+09    ryanmaxwell_1  1.458672e+12  2016-03-22 18:31:42   \n",
       "1  2.571870e+09  detroitdailynew  1.476133e+12  2016-10-10 20:57:00   \n",
       "2  1.710805e+09       cookncooks  1.487767e+12  2017-02-22 12:43:43   \n",
       "\n",
       "   retweet_count retweeted  favorite_count  \\\n",
       "0            NaN       NaN             NaN   \n",
       "1            0.0     False             0.0   \n",
       "2            NaN       NaN             NaN   \n",
       "\n",
       "                                                text      tweet_id  \\\n",
       "0  #IslamKills Are you trying to say that there w...  7.123460e+17   \n",
       "1  Clinton: Trump should’ve apologized more, atta...  7.855849e+17   \n",
       "2  RT @ltapoll: Who was/is the best president of ...  8.343832e+17   \n",
       "\n",
       "                                              source        hashtags  \\\n",
       "0                                                NaN  [\"IslamKills\"]   \n",
       "1  <a href=\"http://twitterfeed.com\" rel=\"nofollow...              []   \n",
       "2                                                NaN              []   \n",
       "\n",
       "                 expanded_urls  posted mentions  retweeted_status_id  \\\n",
       "0                           []  POSTED       []                  NaN   \n",
       "1  [\"http://detne.ws/2e172jF\"]  POSTED       []                  NaN   \n",
       "2                           []  POSTED       []                  NaN   \n",
       "\n",
       "   in_reply_to_status_id  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.read_csv('../data_files/tweets.csv.zip')\n",
    "text.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:42:10.663584Z",
     "start_time": "2020-11-07T00:42:10.652086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_key</th>\n",
       "      <th>created_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ryanmaxwell_1</td>\n",
       "      <td>2016-03-22 18:31:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detroitdailynew</td>\n",
       "      <td>2016-10-10 20:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookncooks</td>\n",
       "      <td>2017-02-22 12:43:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_key          created_str\n",
       "0    ryanmaxwell_1  2016-03-22 18:31:42\n",
       "1  detroitdailynew  2016-10-10 20:57:00\n",
       "2       cookncooks  2017-02-22 12:43:43"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_details = text[['user_key', 'created_str']]\n",
    "tweets_details.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:42:25.544121Z",
     "start_time": "2020-11-07T00:42:25.541911Z"
    }
   },
   "outputs": [],
   "source": [
    "proc_tweets = df.processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:15:06.838253Z",
     "start_time": "2020-11-07T00:15:06.835938Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(#ngram_range=(1, 2),\n",
    "                             binary=True\n",
    "                             stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:19:31.163280Z",
     "start_time": "2020-11-07T00:18:37.230145Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nmf_cv = NMF(n_components=12)\n",
    "\n",
    "# pipeline of cv and nmf, fit and applied to docs: \n",
    "\n",
    "nfm_transformer = Pipeline([('cv', vectorizer),\n",
    "                           ('nmf', nmf_cv)])\n",
    "\n",
    "nmf_matrix = nfm_transformer.fit(proc_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:42:42.637692Z",
     "start_time": "2020-11-07T00:42:42.634027Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:19:37.235956Z",
     "start_time": "2020-11-07T00:19:35.757635Z"
    }
   },
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "display_topics(nmf_cv, terms, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:43:04.708901Z",
     "start_time": "2020-11-07T00:43:04.706381Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,3),\n",
    "                             use_idf=True, \n",
    "                             smooth_idf=True,\n",
    "                             stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:53:30.770508Z",
     "start_time": "2020-11-07T00:49:42.460081Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scrapfish/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 39s, sys: 17.9 s, total: 4min 57s\n",
      "Wall time: 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nmf_tfidf = NMF(n_components=16, random_state=42)\n",
    "\n",
    "# pipeline of cv and nmf, fit and applied to docs: \n",
    "\n",
    "nfm_transformer = Pipeline([('tfidf', tfidf),\n",
    "                           ('nmf', nmf_tfidf)])\n",
    "\n",
    "nmf_matrix = nfm_transformer.fit_transform(proc_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:53:36.412976Z",
     "start_time": "2020-11-07T00:53:32.935657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "donald, donald trump, real, real donald trump, real donald, trump, donald trump hillary, donald trump trump, trump real, trump real donald, trump hillary, donald trump make, maga, trump hillary clinton, donald trump president, trump trump, donald trump say, country, clinton real, support\n",
      "\n",
      "Topic  1\n",
      "twitter, conservative, conservative twitter, christian conservative, christian, christian conservative twitter, conservative twitter christian, twitter christian, twitter christian conservative, tea, party, tea party, twitter conservative, conservative twitter conservative, twitter conservative twitter, gop, twitter patriot, conservative twitter patriot, twitter patriot journalist, conservative twitter tea\n",
      "\n",
      "Topic  2\n",
      "hillary, clinton, hillary clinton, email, campaign, politic, crook, crook hillary, lie, trump hillary, clinton campaign, prison, foundation, obama, trust, trust hillary, clinton foundation, fbi, thing trust, thing trust hillary\n",
      "\n",
      "Topic  3\n",
      "isis, ice isis, ice, target, op ice, op ice isis, isis account, isis op, target isis account, isis account target, isis op ice, ice isis op, account target, target ice isis, target ice, account target ice, target isis, op, account, islam\n",
      "\n",
      "Topic  4\n",
      "trump, say, politic, donald, donald trump, supporter, news, trump trump, trump train, train, trump supporter, celebrate, celebrate trump, maga, favorite, headline, trump favorite, favorite headline, trump favorite headline, new\n",
      "\n",
      "Topic  5\n",
      "america, great, make, make america, america great, make america great, trump make, trump make america, wake, wake america, great trump, america great trump, donald trump make, great trump president, let, let make, let make america, day, trump train, train\n",
      "\n",
      "Topic  6\n",
      "black, live, matt, live matt, black live, black live matt, white, people, police, man, black people, obama, racist, cop, woman, movement, kill, support, need, think\n",
      "\n",
      "Topic  7\n",
      "merkel, muss, merkel muss, die, ist, sie, merkel merkel, merkel merkel muss, girlstalkselfies, frau, merkel muss girlstalkselfies, muss girlstalkselfies, frau merkel, deutschland, hat, merkel ist, es, cdu, zu, wird\n",
      "\n",
      "Topic  8\n",
      "debate, topic, reject, reject debate, debate topic, reject debate topic, alternative debate, alternative, debate night, night, gop debate, gop, vegasgop, vegasgop debate, presidential, presidential debate, reject topic, night debate, debate topic hillary, topic hillary\n",
      "\n",
      "Topic  9\n",
      "patriot, network, journalist network, patriot journalist, patriot journalist network, journalist, cruz, twitter patriot journalist, twitter patriot, conservative twitter patriot, cruz crow, crow, crow patriot, cruz crow patriot, crow patriot journalist, ted, ted cruz, wake america, wake, obama\n",
      "\n",
      "Topic  10\n",
      "love, love love, god, hate, love trump, true, think, fall, fall love, true love, love america, trump love, thank, ilove, ilove butihate, butihate, love say, god love, want, think love\n",
      "\n",
      "Topic  11\n",
      "know, right, right know, good, islam, kill, say, want, islam kill, need, obama, stop, let, think, stop islam, prayforbrussels, brussels, know know, refugee, come\n",
      "\n",
      "Topic  12\n",
      "phrase, hate, make, make hate, hate phrase, make hate phrase, dinner, ruin dinner, ruin, dinner phrase, ruin dinner phrase, eat, think, food, wrong, really, let, thanksgiving, sure, trump make hate\n",
      "\n",
      "Topic  13\n",
      "idea, gift, gift idea, idea politician, gift idea politician, politician, good, soul, christmas, card, sense, book, morning, idea politician soul, politician soul, common, common sense, truth, idea politician common, politician common sense\n",
      "\n",
      "Topic  14\n",
      "like, thing, people, look, thing people, trust, twitter like, people twitter, people twitter like, thing people twitter, trust hillary, thing trust hillary, thing trust, good, look like, say, twitter, day, want, think\n",
      "\n",
      "Topic  15\n",
      "president, trump president, run, run president, trump, obama, president trump, president obama, donald trump president, trump trump president, maga trump president, electionday, maga trump, hillary trump president, elect, maga, great trump president, great trump, america great trump, hillary trump\n"
     ]
    }
   ],
   "source": [
    "terms = tfidf.get_feature_names()\n",
    "\n",
    "display_topics(nmf_tfidf, terms, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:54:03.439395Z",
     "start_time": "2020-11-07T00:54:03.435863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:54:17.791383Z",
     "start_time": "2020-11-07T00:54:17.787727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic_0',\n",
       " 'topic_1',\n",
       " 'topic_2',\n",
       " 'topic_3',\n",
       " 'topic_4',\n",
       " 'topic_5',\n",
       " 'topic_6',\n",
       " 'topic_7',\n",
       " 'topic_8',\n",
       " 'topic_9',\n",
       " 'topic_10',\n",
       " 'topic_11',\n",
       " 'topic_12',\n",
       " 'topic_13',\n",
       " 'topic_14',\n",
       " 'topic_15']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_cols = [f'topic_{x}' for x in range(nmf_matrix.shape[1])]\n",
    "topic_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T00:54:22.219771Z",
     "start_time": "2020-11-07T00:54:22.204955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>1.131815e-03</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.015512</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.068372e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.038215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_0   topic_1   topic_2       topic_3   topic_4   topic_5   topic_6  \\\n",
       "0      0.0  0.000564  0.000688  1.131815e-03  0.003101  0.000887  0.001131   \n",
       "1      0.0  0.000000  0.015240  0.000000e+00  0.017806  0.000000  0.000000   \n",
       "2      0.0  0.000315  0.000000  2.068372e-07  0.000000  0.000000  0.000000   \n",
       "\n",
       "    topic_7   topic_8   topic_9  topic_10  topic_11  topic_12  topic_13  \\\n",
       "0  0.000427  0.000000  0.000216  0.000374  0.015512  0.000233  0.000000   \n",
       "1  0.000000  0.000031  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000072  0.000000  0.000289  0.000000  0.000071  0.000075   \n",
       "\n",
       "   topic_14  topic_15  \n",
       "0  0.002951  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000352  0.038215  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_matrix = pd.DataFrame(nmf_matrix, columns=topic_cols)\n",
    "doc_topic_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
