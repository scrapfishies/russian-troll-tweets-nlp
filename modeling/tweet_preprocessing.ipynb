{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:05.392741Z",
     "start_time": "2020-11-05T23:12:02.750985Z"
    }
   },
   "outputs": [],
   "source": [
    "# DS essentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# python support\n",
    "import re\n",
    "import string\n",
    "import datetime\n",
    "import pickle \n",
    "from collections import Counter\n",
    "\n",
    "# visualizations\n",
    "from wordcloud import WordCloud\n",
    "from nltk import FreqDist\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import words, stopwords, wordnet\n",
    "\n",
    "# spacy\n",
    "import spacy\n",
    "\n",
    "from preprocessing_funcs import clean_tweet, get_hashtags, hashtag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:06.674821Z",
     "start_time": "2020-11-05T23:12:05.395318Z"
    }
   },
   "outputs": [],
   "source": [
    "text = pd.read_csv('../data_files/tweets.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:06.704159Z",
     "start_time": "2020-11-05T23:12:06.680540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_key</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>source</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>posted</th>\n",
       "      <th>mentions</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.868981e+09</td>\n",
       "      <td>ryanmaxwell_1</td>\n",
       "      <td>1.458672e+12</td>\n",
       "      <td>2016-03-22 18:31:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>7.123460e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"IslamKills\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.571870e+09</td>\n",
       "      <td>detroitdailynew</td>\n",
       "      <td>1.476133e+12</td>\n",
       "      <td>2016-10-10 20:57:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>7.855849e+17</td>\n",
       "      <td>&lt;a href=\"http://twitterfeed.com\" rel=\"nofollow...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"http://detne.ws/2e172jF\"]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.710805e+09</td>\n",
       "      <td>cookncooks</td>\n",
       "      <td>1.487767e+12</td>\n",
       "      <td>2017-02-22 12:43:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>8.343832e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.584153e+09</td>\n",
       "      <td>queenofthewo</td>\n",
       "      <td>1.482765e+12</td>\n",
       "      <td>2016-12-26 15:06:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>8.134006e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"ChristmasAftermath\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.768260e+09</td>\n",
       "      <td>mrclydepratt</td>\n",
       "      <td>1.501987e+12</td>\n",
       "      <td>2017-08-06 02:36:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>8.940243e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id         user_key    created_at          created_str  \\\n",
       "0  1.868981e+09    ryanmaxwell_1  1.458672e+12  2016-03-22 18:31:42   \n",
       "1  2.571870e+09  detroitdailynew  1.476133e+12  2016-10-10 20:57:00   \n",
       "2  1.710805e+09       cookncooks  1.487767e+12  2017-02-22 12:43:43   \n",
       "3  2.584153e+09     queenofthewo  1.482765e+12  2016-12-26 15:06:41   \n",
       "4  1.768260e+09     mrclydepratt  1.501987e+12  2017-08-06 02:36:24   \n",
       "\n",
       "   retweet_count retweeted  favorite_count  \\\n",
       "0            NaN       NaN             NaN   \n",
       "1            0.0     False             0.0   \n",
       "2            NaN       NaN             NaN   \n",
       "3            NaN       NaN             NaN   \n",
       "4            NaN       NaN             NaN   \n",
       "\n",
       "                                                text      tweet_id  \\\n",
       "0  #IslamKills Are you trying to say that there w...  7.123460e+17   \n",
       "1  Clinton: Trump should’ve apologized more, atta...  7.855849e+17   \n",
       "2  RT @ltapoll: Who was/is the best president of ...  8.343832e+17   \n",
       "3  RT @jww372: I don't have to guess your religio...  8.134006e+17   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...  8.940243e+17   \n",
       "\n",
       "                                              source                hashtags  \\\n",
       "0                                                NaN          [\"IslamKills\"]   \n",
       "1  <a href=\"http://twitterfeed.com\" rel=\"nofollow...                      []   \n",
       "2                                                NaN                      []   \n",
       "3                                                NaN  [\"ChristmasAftermath\"]   \n",
       "4                                                NaN                      []   \n",
       "\n",
       "                 expanded_urls  posted mentions  retweeted_status_id  \\\n",
       "0                           []  POSTED       []                  NaN   \n",
       "1  [\"http://detne.ws/2e172jF\"]  POSTED       []                  NaN   \n",
       "2                           []  POSTED       []                  NaN   \n",
       "3                           []  POSTED       []                  NaN   \n",
       "4                           []  POSTED       []                  NaN   \n",
       "\n",
       "   in_reply_to_status_id  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:06.754558Z",
     "start_time": "2020-11-05T23:12:06.705827Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = text[['text']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:06.766314Z",
     "start_time": "2020-11-05T23:12:06.758738Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  #IslamKills Are you trying to say that there w...\n",
       "1  Clinton: Trump should’ve apologized more, atta...\n",
       "2  RT @ltapoll: Who was/is the best president of ...\n",
       "3  RT @jww372: I don't have to guess your religio...\n",
       "4  RT @Shareblue: Pence and his lawyers decided w..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:12.904901Z",
     "start_time": "2020-11-05T23:12:06.768916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.06 s, sys: 31.2 ms, total: 6.09 s\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets['clean'] = tweets['text'].map(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:12.912756Z",
     "start_time": "2020-11-05T23:12:12.906512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islamkills are you trying to say that there we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \n",
       "0  islamkills are you trying to say that there we...  \n",
       "1  clinton trump should ve apologized more attack...  \n",
       "2  who was is the best president of the past year...  \n",
       "3  i don t have to guess your religion christmasa...  \n",
       "4  pence and his lawyers decided which of his off...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtag segmenting and acronym parsing\n",
    "\n",
    "`hashtag_dict` contains hashtags and acronyms that keep popping up as being very frequently used and/or in topic modeling. Creating a big dictionary to segment or parse these as part of the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:22.887261Z",
     "start_time": "2020-11-05T23:12:12.914538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.89 s, sys: 26.8 ms, total: 9.92 s\n",
      "Wall time: 9.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets['clean'] = tweets['clean'].replace(hashtag_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:22.900516Z",
     "start_time": "2020-11-05T23:12:22.889545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islam kills are you trying to say that there w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \n",
       "0  islam kills are you trying to say that there w...  \n",
       "1  clinton trump should ve apologized more attack...  \n",
       "2  who was is the best president of the past year...  \n",
       "3  i don t have to guess your religion christmas ...  \n",
       "4  pence and his lawyers decided which of his off...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unwanted words\n",
    "\n",
    "- lots of german\n",
    "- stop words\n",
    "- other weird words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniquely German Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:23.029915Z",
     "start_time": "2020-11-05T23:12:22.902168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236736, list)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of all english words known to nltk\n",
    "english_words = list(nltk.corpus.words.words())\n",
    "english_words = [word.lower() for word in english_words]\n",
    "len(english_words), type(english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:24.258777Z",
     "start_time": "2020-11-05T23:12:23.031599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147306, list)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_net = list(nltk.corpus.wordnet.words())\n",
    "word_net = [word.lower() for word in word_net]\n",
    "len(word_net), type(word_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:24.324032Z",
     "start_time": "2020-11-05T23:12:24.260324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323592, set)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "many_english_words = set(english_words + word_net)\n",
    "len(many_english_words), type(many_english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:24.836115Z",
     "start_time": "2020-11-05T23:12:24.325900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556226, list)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus.europarl_raw import german\n",
    "\n",
    "german = list(german.words())\n",
    "german = [word.lower() for word in german]\n",
    "len(german), type(german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:24.843805Z",
     "start_time": "2020-11-05T23:12:24.837694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, list)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_stop_words = stopwords.words(\"german\")\n",
    "len(german_stop_words), type(german_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:24.896228Z",
     "start_time": "2020-11-05T23:12:24.845580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29839"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_words = set(german + german_stop_words)\n",
    "len(german_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.041286Z",
     "start_time": "2020-11-05T23:12:24.897944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28154"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_german = set([word.lower() for word in german if word not in many_english_words])\n",
    "len(unique_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.074846Z",
     "start_time": "2020-11-05T23:12:25.070231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179, list)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_stop_words = stopwords.words(\"english\")\n",
    "print(standard_stop_words)\n",
    "len(standard_stop_words), type(standard_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.084542Z",
     "start_time": "2020-11-05T23:12:25.079405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some twitter stopwords\n",
    "\n",
    "with open('../data_files/twitter_stopwords.txt') as f:\n",
    "    words = f.read().split(',')\n",
    "    twitter_stopwords = list(words)\n",
    "    twitter_stopwords = [word.lower() for word in twitter_stopwords]\n",
    "\n",
    "len(twitter_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.088733Z",
     "start_time": "2020-11-05T23:12:25.086418Z"
    }
   },
   "outputs": [],
   "source": [
    "# other things that have popped up in preprocessing\n",
    "other_stops = ['amp', '…', 'll', '\\ufeff1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.092514Z",
     "start_time": "2020-11-05T23:12:25.090307Z"
    }
   },
   "outputs": [],
   "source": [
    "english_stops = set(standard_stop_words + twitter_stopwords + other_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.096220Z",
     "start_time": "2020-11-05T23:12:25.094050Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_eng_germ = set(list(english_stops) + list(german_stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.100735Z",
     "start_time": "2020-11-05T23:12:25.097668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords_eng_germ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.104016Z",
     "start_time": "2020-11-05T23:12:25.102144Z"
    }
   },
   "outputs": [],
   "source": [
    "# save stopwords for later\n",
    "# with open(\"../data_files/stopwords_eng_germ.txt\", \"w\") as outfile:\n",
    "#     outfile.write(\",\".join(str(word) for word in stopwords_eng_germ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big word removal set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.113379Z",
     "start_time": "2020-11-05T23:12:25.105499Z"
    }
   },
   "outputs": [],
   "source": [
    "words_to_remove = set(list(unique_german) + list(english_stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.117869Z",
     "start_time": "2020-11-05T23:12:25.114936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28768, set)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_remove), type(words_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.866998Z",
     "start_time": "2020-11-05T23:12:25.119562Z"
    }
   },
   "outputs": [],
   "source": [
    "# keep ner, entity_linker\n",
    "disabled_components = ['parser', 'tagger']\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=disabled_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.870572Z",
     "start_time": "2020-11-05T23:12:25.868372Z"
    }
   },
   "outputs": [],
   "source": [
    "#nlp.add_pipe(nlp.create_pipe('sentencizer'), n_threads=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.874506Z",
     "start_time": "2020-11-05T23:12:25.872116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ner', 'sentencizer']\n"
     ]
    }
   ],
   "source": [
    "#print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.877870Z",
     "start_time": "2020-11-05T23:12:25.875768Z"
    }
   },
   "outputs": [],
   "source": [
    "# as much as it pains me...\n",
    "def get_me_mike_pence(text):\n",
    "    return text.replace(\"penny\", \"pence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:12:25.883046Z",
     "start_time": "2020-11-05T23:12:25.879362Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_pipe(doc):\n",
    "    lemma_list = [str(tok.lemma_) for tok in doc\n",
    "                 if tok.is_alpha and tok.text not in words_to_remove]\n",
    "    lem_string = \" \".join(lemma_list)\n",
    "    # get back mike pence\n",
    "    lem_string = get_me_mike_pence(lem_string)\n",
    "    return lem_string\n",
    "\n",
    "def preprocess_pipe(texts, batch_size=100):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=batch_size, n_threads=-1):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:14:33.305234Z",
     "start_time": "2020-11-05T23:12:25.884681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 42s, sys: 23.4 s, total: 2min 6s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets['processed'] = preprocess_pipe(tweets['clean'], batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:14:33.314128Z",
     "start_time": "2020-11-05T23:14:33.306978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islam kills are you trying to say that there w...</td>\n",
       "      <td>islam kill try say terrorist attack europe ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "      <td>clinton trump apologize attack little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "      <td>well president past retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmas ...</td>\n",
       "      <td>guess religion christmas aftermath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "      <td>pence lawyer decide official email public can see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  islam kills are you trying to say that there w...   \n",
       "1  clinton trump should ve apologized more attack...   \n",
       "2  who was is the best president of the past year...   \n",
       "3  i don t have to guess your religion christmas ...   \n",
       "4  pence and his lawyers decided which of his off...   \n",
       "\n",
       "                                           processed  \n",
       "0  islam kill try say terrorist attack europe ref...  \n",
       "1              clinton trump apologize attack little  \n",
       "2                        well president past retweet  \n",
       "3                 guess religion christmas aftermath  \n",
       "4  pence lawyer decide official email public can see  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequencies\n",
    "\n",
    "Finding most frequent words that might need cleaning still, especially hashtags and acronyms that might need to be added to the dictionary above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:14:33.319247Z",
     "start_time": "2020-11-05T23:14:33.315742Z"
    }
   },
   "outputs": [],
   "source": [
    "# top words in processed that are NOT in many_english_words\n",
    "def word_freq(text, num_words=10, freq_thresh=1000):\n",
    "    all_words = []\n",
    "    for tweet in list(text):\n",
    "        words = tweet.split()\n",
    "        for word in words:\n",
    "            if word not in many_english_words:\n",
    "                all_words.append(word.lower())\n",
    "    \n",
    "    top_words = Counter(all_words).most_common(num_words)\n",
    "    \n",
    "    results_list = []\n",
    "    for pair in top_words:\n",
    "        if pair[1] > freq_thresh:\n",
    "            results_list.append(pair)\n",
    "            \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:14:33.975605Z",
     "start_time": "2020-11-05T23:14:33.320924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('obama', 9788),\n",
       " ('has', 6150),\n",
       " ('conservatives', 5824),\n",
       " ('says', 3105),\n",
       " ('potus', 2120),\n",
       " ('merkel', 2092),\n",
       " ('women', 2058),\n",
       " ('rt', 2051),\n",
       " ('ll', 1913),\n",
       " ('cruz', 1910)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq(tweets['clean'], num_words=10, freq_thresh=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:14:34.391936Z",
     "start_time": "2020-11-05T23:14:33.977313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('obama', 9788),\n",
       " ('\\ufeff1', 2388),\n",
       " ('potus', 2120),\n",
       " ('merkel', 2092),\n",
       " ('cruz', 1910),\n",
       " ('gt', 1657),\n",
       " ('cnn', 1547),\n",
       " ('americans', 1517),\n",
       " ('dnc', 1453),\n",
       " ('htt', 1289)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq(tweets['processed'], num_words=10, freq_thresh=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle clean tweets for later use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:14:34.400093Z",
     "start_time": "2020-11-05T23:14:34.393715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islam kills are you trying to say that there w...</td>\n",
       "      <td>islam kill try say terrorist attack europe ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "      <td>clinton trump apologize attack little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "      <td>well president past retweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  islam kills are you trying to say that there w...   \n",
       "1  clinton trump should ve apologized more attack...   \n",
       "2  who was is the best president of the past year...   \n",
       "\n",
       "                                           processed  \n",
       "0  islam kill try say terrorist attack europe ref...  \n",
       "1              clinton trump apologize attack little  \n",
       "2                        well president past retweet  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:14:34.440275Z",
     "start_time": "2020-11-05T23:14:34.401776Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = tweets[['text', 'processed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:14:34.444842Z",
     "start_time": "2020-11-05T23:14:34.442597Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('../data_files/processed_tweets.pickle', 'wb') as to_write:\n",
    "#    pickle.dump(tweets, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
