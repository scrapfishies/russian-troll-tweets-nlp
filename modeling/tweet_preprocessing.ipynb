{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:04:12.249817Z",
     "start_time": "2020-11-04T23:04:10.148113Z"
    }
   },
   "outputs": [],
   "source": [
    "# DS essentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# python support\n",
    "import re\n",
    "import string\n",
    "import datetime\n",
    "import pickle \n",
    "from collections import Counter\n",
    "\n",
    "# visualizations\n",
    "from wordcloud import WordCloud\n",
    "from nltk import FreqDist\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import words, stopwords, wordnet\n",
    "\n",
    "# spacy\n",
    "import spacy\n",
    "\n",
    "from preprocessing_funcs import clean_tweet, get_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:04:13.367587Z",
     "start_time": "2020-11-04T23:04:12.252174Z"
    }
   },
   "outputs": [],
   "source": [
    "text = pd.read_csv('../data_files/tweets.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:04:13.392346Z",
     "start_time": "2020-11-04T23:04:13.369950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_key</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>source</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>posted</th>\n",
       "      <th>mentions</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.868981e+09</td>\n",
       "      <td>ryanmaxwell_1</td>\n",
       "      <td>1.458672e+12</td>\n",
       "      <td>2016-03-22 18:31:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>7.123460e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"IslamKills\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.571870e+09</td>\n",
       "      <td>detroitdailynew</td>\n",
       "      <td>1.476133e+12</td>\n",
       "      <td>2016-10-10 20:57:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>7.855849e+17</td>\n",
       "      <td>&lt;a href=\"http://twitterfeed.com\" rel=\"nofollow...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"http://detne.ws/2e172jF\"]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.710805e+09</td>\n",
       "      <td>cookncooks</td>\n",
       "      <td>1.487767e+12</td>\n",
       "      <td>2017-02-22 12:43:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>8.343832e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.584153e+09</td>\n",
       "      <td>queenofthewo</td>\n",
       "      <td>1.482765e+12</td>\n",
       "      <td>2016-12-26 15:06:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>8.134006e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"ChristmasAftermath\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.768260e+09</td>\n",
       "      <td>mrclydepratt</td>\n",
       "      <td>1.501987e+12</td>\n",
       "      <td>2017-08-06 02:36:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>8.940243e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id         user_key    created_at          created_str  \\\n",
       "0  1.868981e+09    ryanmaxwell_1  1.458672e+12  2016-03-22 18:31:42   \n",
       "1  2.571870e+09  detroitdailynew  1.476133e+12  2016-10-10 20:57:00   \n",
       "2  1.710805e+09       cookncooks  1.487767e+12  2017-02-22 12:43:43   \n",
       "3  2.584153e+09     queenofthewo  1.482765e+12  2016-12-26 15:06:41   \n",
       "4  1.768260e+09     mrclydepratt  1.501987e+12  2017-08-06 02:36:24   \n",
       "\n",
       "   retweet_count retweeted  favorite_count  \\\n",
       "0            NaN       NaN             NaN   \n",
       "1            0.0     False             0.0   \n",
       "2            NaN       NaN             NaN   \n",
       "3            NaN       NaN             NaN   \n",
       "4            NaN       NaN             NaN   \n",
       "\n",
       "                                                text      tweet_id  \\\n",
       "0  #IslamKills Are you trying to say that there w...  7.123460e+17   \n",
       "1  Clinton: Trump should’ve apologized more, atta...  7.855849e+17   \n",
       "2  RT @ltapoll: Who was/is the best president of ...  8.343832e+17   \n",
       "3  RT @jww372: I don't have to guess your religio...  8.134006e+17   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...  8.940243e+17   \n",
       "\n",
       "                                              source                hashtags  \\\n",
       "0                                                NaN          [\"IslamKills\"]   \n",
       "1  <a href=\"http://twitterfeed.com\" rel=\"nofollow...                      []   \n",
       "2                                                NaN                      []   \n",
       "3                                                NaN  [\"ChristmasAftermath\"]   \n",
       "4                                                NaN                      []   \n",
       "\n",
       "                 expanded_urls  posted mentions  retweeted_status_id  \\\n",
       "0                           []  POSTED       []                  NaN   \n",
       "1  [\"http://detne.ws/2e172jF\"]  POSTED       []                  NaN   \n",
       "2                           []  POSTED       []                  NaN   \n",
       "3                           []  POSTED       []                  NaN   \n",
       "4                           []  POSTED       []                  NaN   \n",
       "\n",
       "   in_reply_to_status_id  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:04:13.436311Z",
     "start_time": "2020-11-04T23:04:13.394155Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = text[['text']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:04:13.444498Z",
     "start_time": "2020-11-04T23:04:13.438032Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  #IslamKills Are you trying to say that there w...\n",
       "1  Clinton: Trump should’ve apologized more, atta...\n",
       "2  RT @ltapoll: Who was/is the best president of ...\n",
       "3  RT @jww372: I don't have to guess your religio...\n",
       "4  RT @Shareblue: Pence and his lawyers decided w..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:04:19.697846Z",
     "start_time": "2020-11-04T23:04:13.449010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.16 s, sys: 51.1 ms, total: 6.21 s\n",
      "Wall time: 6.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets['clean'] = tweets['text'].map(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:04:19.707164Z",
     "start_time": "2020-11-04T23:04:19.700935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islamkills are you trying to say that there we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \n",
       "0  islamkills are you trying to say that there we...  \n",
       "1  clinton trump should ve apologized more attack...  \n",
       "2  who was is the best president of the past year...  \n",
       "3  i don t have to guess your religion christmasa...  \n",
       "4  pence and his lawyers decided which of his off...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtag segmenting and acronym parsing\n",
    "\n",
    "These are hashtags and acronyms that keep popping up as being very frequently used and/or in topic modeling. Creating a big dictionary to segment or parse these as part of the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:05:06.105677Z",
     "start_time": "2020-11-04T23:05:06.100562Z"
    }
   },
   "outputs": [],
   "source": [
    "hashtag_dict = {'realdonaldtrump': 'real donald trump',\n",
    "                'hillaryclinton': 'hillary clinton', \n",
    "                'wakeupamerica': 'wake up america', \n",
    "                'neverhillary': 'never hillary',\n",
    "                'trumpforpresident': 'trump for president', \n",
    "                'islamkills': 'islam kills',\n",
    "                'blacklivesmatter': 'black lives matter',\n",
    "                'survivalguidetothanksgiving': 'survival guide to thanksgiving',\n",
    "                'christmasaftermath': 'christmas aftermath',\n",
    "                'teaparty': 'tea party',\n",
    "                'betteralternativetodebates': 'better alternative to debates',\n",
    "                'crookedhillary': 'crooked hillary',\n",
    "                'thingsmoretrustedthanhillary': 'things more trusted than hillary',\n",
    "                'ruinadinnerinonephrase': 'ruin a dinner in one phrase',\n",
    "                'makemehateyouinonephrase': 'make me hate you in one phrase',\n",
    "                'idrunforpresidentif': 'id run for president if',\n",
    "                'ihavearighttoknow': 'i have a right to know',\n",
    "                'hrc': 'hillary clinton',\n",
    "                'foxnews': 'fox news', \n",
    "                'stopislam': 'stop islam',\n",
    "                'icelebratetrumpwith': 'i celebrate trump with',\n",
    "                'reasonstoprotest': 'reasons to protest',\n",
    "                'trumpsfavoriteheadline': 'trumps favorite headline',\n",
    "                'merkelmussbleiben': 'merkel muss bleiben',\n",
    "                'rejecteddebatetopics': 'rejected debate topics',\n",
    "                'makeamericagreatagain': 'make america great again',\n",
    "                'todolistbeforechristmas': 'to',\n",
    "                'debatenight': 'debate night',\n",
    "                'cruzcrew': 'cruz crew',\n",
    "                'tedcruz': 'ted cruz',\n",
    "                'draintheswamp': 'drain the swamp',\n",
    "                'potuslasttweet': 'potus last tweet',\n",
    "                'giftideasforpoliticians': 'gift ideas for politicians', \n",
    "                'hillaryshealth': 'hillarys health',\n",
    "                'hillaryforprison': 'hillary for prison',\n",
    "                'thingspeopleontwitterlike': 'things people on twitter like',\n",
    "                'obamaswishlist': 'obamas wish list',\n",
    "                'trumpbecause': 'trump because',\n",
    "                'nocybercensorship': 'no cyber censorship',\n",
    "                'votetrump': 'vote trump',\n",
    "                'nevertrump': 'never trump',\n",
    "                'americafirst': 'america first',\n",
    "                'demdebate': 'dem debate',\n",
    "                'gopdebate': 'gop debate',\n",
    "                'rednationrising': 'red nation rising',\n",
    "                'hillarysemails': 'hillarys emails',\n",
    "                'clintonoriginalbirther': 'clinton orginal birther',\n",
    "                'trumptrain': 'trump train',\n",
    "                'oscarhasnocolor': 'oscar has no color', \n",
    "                'clintonoriginalbirther': 'clinton original birther',\n",
    "                'basketofdeplorables': 'basket of deplorables',\n",
    "                'billclinton': 'bill clinton',\n",
    "                'imwithher': 'im with her',\n",
    "                'nowplaying': 'now playing',\n",
    "                'opiceisis': 'op ice isis',\n",
    "                'iceisis': 'ice isis', \n",
    "                'tcot': 'top conservatives on twitter',\n",
    "                'ccot': 'christian conservatives on twitter',\n",
    "                'pjnet': 'patriot journalist network'\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:05:18.336024Z",
     "start_time": "2020-11-04T23:05:07.946268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 55.6 ms, total: 10.3 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets['clean'] = tweets['clean'].replace(hashtag_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:05:18.533219Z",
     "start_time": "2020-11-04T23:05:18.526121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islam kills are you trying to say that there w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \n",
       "0  islam kills are you trying to say that there w...  \n",
       "1  clinton trump should ve apologized more attack...  \n",
       "2  who was is the best president of the past year...  \n",
       "3  i don t have to guess your religion christmas ...  \n",
       "4  pence and his lawyers decided which of his off...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unwanted words\n",
    "\n",
    "- lots of german\n",
    "- stop words\n",
    "- other weird words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniquely German Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:06:45.253051Z",
     "start_time": "2020-11-04T23:06:45.126566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236736, list)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of all english words known to nltk\n",
    "english_words = list(nltk.corpus.words.words())\n",
    "english_words = [word.lower() for word in english_words]\n",
    "len(english_words), type(english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:06:46.209462Z",
     "start_time": "2020-11-04T23:06:46.179388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147306, list)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_net = list(nltk.corpus.wordnet.words())\n",
    "word_net = [word.lower() for word in word_net]\n",
    "len(word_net), type(word_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:06:47.405438Z",
     "start_time": "2020-11-04T23:06:47.334296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323592, set)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "many_english_words = set(english_words + word_net)\n",
    "len(many_english_words), type(many_english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:06:49.463621Z",
     "start_time": "2020-11-04T23:06:48.923006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556226, list)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus.europarl_raw import german\n",
    "\n",
    "german = list(german.words())\n",
    "german = [word.lower() for word in german]\n",
    "len(german), type(german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:06:51.029894Z",
     "start_time": "2020-11-04T23:06:51.025262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, list)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_stop_words = stopwords.words(\"german\")\n",
    "len(german_stop_words), type(german_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:06:52.606993Z",
     "start_time": "2020-11-04T23:06:52.553795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29839"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_words = set(german + german_stop_words)\n",
    "len(german_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:06:54.409759Z",
     "start_time": "2020-11-04T23:06:54.253957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28154"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_german = set([word.lower() for word in german if word not in many_english_words])\n",
    "len(unique_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:06:56.087180Z",
     "start_time": "2020-11-04T23:06:56.082472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179, list)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_stop_words = stopwords.words(\"english\")\n",
    "print(standard_stop_words)\n",
    "len(standard_stop_words), type(standard_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:06:59.482108Z",
     "start_time": "2020-11-04T23:06:59.475546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some twitter stopwords\n",
    "\n",
    "with open('../data_files/twitter_stopwords.txt') as f:\n",
    "    words = f.read().split(',')\n",
    "    twitter_stopwords = list(words)\n",
    "    twitter_stopwords = [word.lower() for word in twitter_stopwords]\n",
    "\n",
    "len(twitter_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:09:49.136790Z",
     "start_time": "2020-11-04T23:09:49.134520Z"
    }
   },
   "outputs": [],
   "source": [
    "# other things that have popped up in preprocessing\n",
    "other_stops = ['amp', '…', 'll', '\\ufeff1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:09:52.798055Z",
     "start_time": "2020-11-04T23:09:52.795538Z"
    }
   },
   "outputs": [],
   "source": [
    "english_stops = set(standard_stop_words + twitter_stopwords + other_stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big word removal set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:09:58.212720Z",
     "start_time": "2020-11-04T23:09:58.205097Z"
    }
   },
   "outputs": [],
   "source": [
    "words_to_remove = set(list(unique_german) + list(english_stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:09:59.968872Z",
     "start_time": "2020-11-04T23:09:59.965594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28768, set)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_remove), type(words_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:07:16.686701Z",
     "start_time": "2020-11-04T23:07:15.930600Z"
    }
   },
   "outputs": [],
   "source": [
    "# keep ner, entity_linker\n",
    "disabled_components = ['parser', 'tagger']\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=disabled_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:07:18.474330Z",
     "start_time": "2020-11-04T23:07:18.471660Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:07:20.224633Z",
     "start_time": "2020-11-04T23:07:20.222248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ner', 'sentencizer']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:07:21.961729Z",
     "start_time": "2020-11-04T23:07:21.959158Z"
    }
   },
   "outputs": [],
   "source": [
    "# as much as it pains me...\n",
    "def get_me_mike_pence(text):\n",
    "    return text.replace(\"penny\", \"pence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:07:23.710717Z",
     "start_time": "2020-11-04T23:07:23.707078Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_pipe(doc):\n",
    "    lemma_list = [str(tok.lemma_) for tok in doc\n",
    "                 if tok.is_alpha and tok.text not in words_to_remove]\n",
    "    lem_string = \" \".join(lemma_list)\n",
    "    # get back mike pence\n",
    "    lem_string = get_me_mike_pence(lem_string)\n",
    "    return lem_string\n",
    "\n",
    "def preprocess_pipe(texts, batch_size=100):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=batch_size):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:12:07.610026Z",
     "start_time": "2020-11-04T23:10:07.678060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 21.5 s, total: 1min 59s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets['processed'] = preprocess_pipe(tweets['clean'], batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:12:09.390198Z",
     "start_time": "2020-11-04T23:12:09.382984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islam kills are you trying to say that there w...</td>\n",
       "      <td>islam kill try say terrorist attack europe ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "      <td>clinton trump apologize attack little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "      <td>well president past retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmas ...</td>\n",
       "      <td>guess religion christmas aftermath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "      <td>pence lawyer decide official email public can see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  islam kills are you trying to say that there w...   \n",
       "1  clinton trump should ve apologized more attack...   \n",
       "2  who was is the best president of the past year...   \n",
       "3  i don t have to guess your religion christmas ...   \n",
       "4  pence and his lawyers decided which of his off...   \n",
       "\n",
       "                                           processed  \n",
       "0  islam kill try say terrorist attack europe ref...  \n",
       "1              clinton trump apologize attack little  \n",
       "2                        well president past retweet  \n",
       "3                 guess religion christmas aftermath  \n",
       "4  pence lawyer decide official email public can see  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequencies\n",
    "\n",
    "Finding most frequent words that might need cleaning still, especially hashtags and acronyms that might need to be added to the dictionary above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:12:13.113422Z",
     "start_time": "2020-11-04T23:12:13.109882Z"
    }
   },
   "outputs": [],
   "source": [
    "# top words in processed that are NOT in many_english_words\n",
    "def word_freq(text, num_words=10, freq_thresh=1000):\n",
    "    all_words = []\n",
    "    for tweet in list(text):\n",
    "        words = tweet.split()\n",
    "        for word in words:\n",
    "            if word not in many_english_words:\n",
    "                all_words.append(word.lower())\n",
    "    \n",
    "    top_words = Counter(all_words).most_common(num_words)\n",
    "    \n",
    "    results_list = []\n",
    "    for pair in top_words:\n",
    "        if pair[1] > freq_thresh:\n",
    "            results_list.append(pair)\n",
    "            \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:12:15.871375Z",
     "start_time": "2020-11-04T23:12:15.243234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('obama', 9788),\n",
       " ('has', 6150),\n",
       " ('conservatives', 5824),\n",
       " ('says', 3105),\n",
       " ('potus', 2120),\n",
       " ('merkel', 2092),\n",
       " ('women', 2058),\n",
       " ('rt', 2051),\n",
       " ('ll', 1913),\n",
       " ('cruz', 1910)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq(tweets['clean'], num_words=10, freq_thresh=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:12:19.169854Z",
     "start_time": "2020-11-04T23:12:18.733563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('obama', 9788),\n",
       " ('\\ufeff1', 2388),\n",
       " ('potus', 2120),\n",
       " ('merkel', 2092),\n",
       " ('cruz', 1910),\n",
       " ('gt', 1657),\n",
       " ('cnn', 1547),\n",
       " ('americans', 1517),\n",
       " ('dnc', 1453),\n",
       " ('htt', 1289)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq(tweets['processed'], num_words=10, freq_thresh=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle clean tweets for later use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:12:38.466745Z",
     "start_time": "2020-11-04T23:12:38.459678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islam kills are you trying to say that there w...</td>\n",
       "      <td>islam kill try say terrorist attack europe ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "      <td>clinton trump apologize attack little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "      <td>well president past retweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  islam kills are you trying to say that there w...   \n",
       "1  clinton trump should ve apologized more attack...   \n",
       "2  who was is the best president of the past year...   \n",
       "\n",
       "                                           processed  \n",
       "0  islam kill try say terrorist attack europe ref...  \n",
       "1              clinton trump apologize attack little  \n",
       "2                        well president past retweet  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:12:40.302326Z",
     "start_time": "2020-11-04T23:12:40.264221Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = tweets[['text', 'processed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T23:12:42.185470Z",
     "start_time": "2020-11-04T23:12:42.050631Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data_files/processed_tweets.pickle', 'wb') as to_write:\n",
    "   pickle.dump(tweets, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
