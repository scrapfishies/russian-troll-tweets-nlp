{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:14.791676Z",
     "start_time": "2020-10-31T19:03:11.920811Z"
    }
   },
   "outputs": [],
   "source": [
    "# DS essentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# python support\n",
    "import re\n",
    "import string\n",
    "import datetime\n",
    "import pickle \n",
    "from collections import Counter\n",
    "\n",
    "# visualizations\n",
    "from wordcloud import WordCloud\n",
    "from nltk import FreqDist\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words, stopwords, wordnet\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# spacy\n",
    "import spacy\n",
    "\n",
    "from preprocessing_funcs import clean_tweet, get_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:15.747007Z",
     "start_time": "2020-10-31T19:03:14.793931Z"
    }
   },
   "outputs": [],
   "source": [
    "text = pd.read_csv('../data_files/tweets.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:15.769649Z",
     "start_time": "2020-10-31T19:03:15.749249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_key</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>source</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>posted</th>\n",
       "      <th>mentions</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.868981e+09</td>\n",
       "      <td>ryanmaxwell_1</td>\n",
       "      <td>1.458672e+12</td>\n",
       "      <td>2016-03-22 18:31:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>7.123460e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"IslamKills\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.571870e+09</td>\n",
       "      <td>detroitdailynew</td>\n",
       "      <td>1.476133e+12</td>\n",
       "      <td>2016-10-10 20:57:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>7.855849e+17</td>\n",
       "      <td>&lt;a href=\"http://twitterfeed.com\" rel=\"nofollow...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"http://detne.ws/2e172jF\"]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.710805e+09</td>\n",
       "      <td>cookncooks</td>\n",
       "      <td>1.487767e+12</td>\n",
       "      <td>2017-02-22 12:43:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>8.343832e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.584153e+09</td>\n",
       "      <td>queenofthewo</td>\n",
       "      <td>1.482765e+12</td>\n",
       "      <td>2016-12-26 15:06:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>8.134006e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"ChristmasAftermath\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.768260e+09</td>\n",
       "      <td>mrclydepratt</td>\n",
       "      <td>1.501987e+12</td>\n",
       "      <td>2017-08-06 02:36:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>8.940243e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id         user_key    created_at          created_str  \\\n",
       "0  1.868981e+09    ryanmaxwell_1  1.458672e+12  2016-03-22 18:31:42   \n",
       "1  2.571870e+09  detroitdailynew  1.476133e+12  2016-10-10 20:57:00   \n",
       "2  1.710805e+09       cookncooks  1.487767e+12  2017-02-22 12:43:43   \n",
       "3  2.584153e+09     queenofthewo  1.482765e+12  2016-12-26 15:06:41   \n",
       "4  1.768260e+09     mrclydepratt  1.501987e+12  2017-08-06 02:36:24   \n",
       "\n",
       "   retweet_count retweeted  favorite_count  \\\n",
       "0            NaN       NaN             NaN   \n",
       "1            0.0     False             0.0   \n",
       "2            NaN       NaN             NaN   \n",
       "3            NaN       NaN             NaN   \n",
       "4            NaN       NaN             NaN   \n",
       "\n",
       "                                                text      tweet_id  \\\n",
       "0  #IslamKills Are you trying to say that there w...  7.123460e+17   \n",
       "1  Clinton: Trump should’ve apologized more, atta...  7.855849e+17   \n",
       "2  RT @ltapoll: Who was/is the best president of ...  8.343832e+17   \n",
       "3  RT @jww372: I don't have to guess your religio...  8.134006e+17   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...  8.940243e+17   \n",
       "\n",
       "                                              source                hashtags  \\\n",
       "0                                                NaN          [\"IslamKills\"]   \n",
       "1  <a href=\"http://twitterfeed.com\" rel=\"nofollow...                      []   \n",
       "2                                                NaN                      []   \n",
       "3                                                NaN  [\"ChristmasAftermath\"]   \n",
       "4                                                NaN                      []   \n",
       "\n",
       "                 expanded_urls  posted mentions  retweeted_status_id  \\\n",
       "0                           []  POSTED       []                  NaN   \n",
       "1  [\"http://detne.ws/2e172jF\"]  POSTED       []                  NaN   \n",
       "2                           []  POSTED       []                  NaN   \n",
       "3                           []  POSTED       []                  NaN   \n",
       "4                           []  POSTED       []                  NaN   \n",
       "\n",
       "   in_reply_to_status_id  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:15.842737Z",
     "start_time": "2020-10-31T19:03:15.771532Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = text[['user_key', 'text']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:16.635560Z",
     "start_time": "2020-10-31T19:03:15.844887Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets['hashtags'] = tweets['text'].map(get_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:16.674279Z",
     "start_time": "2020-10-31T19:03:16.638623Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = tweets[['user_key', 'hashtags', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:22.254404Z",
     "start_time": "2020-10-31T19:03:16.677089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.56 s, sys: 12.9 ms, total: 5.57 s\n",
      "Wall time: 5.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets['clean'] = tweets['text'].map(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:22.264074Z",
     "start_time": "2020-10-31T19:03:22.255631Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_key</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ryanmaxwell_1</td>\n",
       "      <td>[IslamKills]</td>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islamkills are you trying to say that there we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detroitdailynew</td>\n",
       "      <td>[]</td>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookncooks</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queenofthewo</td>\n",
       "      <td>[ChristmasAftermath]</td>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mrclydepratt</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_key              hashtags  \\\n",
       "0    ryanmaxwell_1          [IslamKills]   \n",
       "1  detroitdailynew                    []   \n",
       "2       cookncooks                    []   \n",
       "3     queenofthewo  [ChristmasAftermath]   \n",
       "4     mrclydepratt                    []   \n",
       "\n",
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \n",
       "0  islamkills are you trying to say that there we...  \n",
       "1  clinton trump should ve apologized more attack...  \n",
       "2  who was is the best president of the past year...  \n",
       "3  i don t have to guess your religion christmasa...  \n",
       "4  pence and his lawyers decided which of his off...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtag Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent important hashtags to parse out and keep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:22.270435Z",
     "start_time": "2020-10-31T19:03:22.265748Z"
    }
   },
   "outputs": [],
   "source": [
    "hashtag_dict = {'realdonaldtrump': 'real donald trump',\n",
    "                    'hillaryclinton': 'hillary clinton', \n",
    "                    'wakeupamerica': 'wake up america', \n",
    "                    'neverhillary': 'never hillary',\n",
    "                    'trumpforpresident': 'trump for president', \n",
    "                    'islamkills': 'islam kills',\n",
    "                    'blacklivesmatter': 'black lives matter',\n",
    "                    'survivalguidetothanksgiving': 'survival guide to thanksgiving',\n",
    "                    'christmasaftermath': 'christmas aftermath',\n",
    "                    'teaparty': 'tea party',\n",
    "                    'betteralternativetodebates': 'better alternative to debates',\n",
    "                    'crookedhillary': 'crooked hillary',\n",
    "                    'thingsmoretrustedthanhillary': 'things more trusted than hillary',\n",
    "                    'ruinadinnerinonephrase': 'ruin a dinner in one phrase',\n",
    "                    'makemehateyouinonephrase': 'make me hate you in one phrase',\n",
    "                    'idrunforpresidentif': 'id run for president if',\n",
    "                    'ihavearighttoknow': 'i have a right to know',\n",
    "                    'hrc': 'hillary clinton',\n",
    "                    'foxnews': 'fox news', \n",
    "                    'stopislam': 'stop islam',\n",
    "                    'icelebratetrumpwith': 'i celebrate trump with',\n",
    "                    'reasonstoprotest': 'reasons to protest',\n",
    "                    'trumpsfavoriteheadline': 'trumps favorite headline',\n",
    "                    'merkelmussbleiben': 'merkel muss bleiben',\n",
    "                    'rejecteddebatetopics': 'rejected debate topics',\n",
    "                    'makeamericagreatagain': 'make america great again',\n",
    "                    'todolistbeforechristmas': 'to',\n",
    "                    'debatenight': 'debate night',\n",
    "                    'cruzcrew': 'cruz crew',\n",
    "                    'tedcruz': 'ted cruz',\n",
    "                    'draintheswamp': 'drain the swamp',\n",
    "                    'potuslasttweet': 'potus last tweet',\n",
    "                    'giftideasforpoliticians': 'gift ideas for politicians', \n",
    "                    'hillaryshealth': 'hillarys health',\n",
    "                    'hillaryforprison': 'hillary for prison',\n",
    "                    'thingspeopleontwitterlike': 'things people on twitter like',\n",
    "                    'obamaswishlist': 'obamas wish list',\n",
    "                    'trumpbecause': 'trump because',\n",
    "                    'nocybercensorship': 'no cyber censorship',\n",
    "                    'votetrump': 'vote trump',\n",
    "                    'nevertrump': 'never trump',\n",
    "                    'americafirst': 'america first',\n",
    "                    'demdebate': 'dem debate',\n",
    "                    'gopdebate': 'gop debate',\n",
    "                    'rednationrising': 'red nation rising'\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:29.583599Z",
     "start_time": "2020-10-31T19:03:22.272018Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets['cleaned_hashtags'] = tweets['clean'].replace(hashtag_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:29.603347Z",
     "start_time": "2020-10-31T19:03:29.586081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_key</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>cleaned_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ryanmaxwell_1</td>\n",
       "      <td>[IslamKills]</td>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islamkills are you trying to say that there we...</td>\n",
       "      <td>islam kills are you trying to say that there w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detroitdailynew</td>\n",
       "      <td>[]</td>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookncooks</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queenofthewo</td>\n",
       "      <td>[ChristmasAftermath]</td>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmasa...</td>\n",
       "      <td>i don t have to guess your religion christmas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mrclydepratt</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_key              hashtags  \\\n",
       "0    ryanmaxwell_1          [IslamKills]   \n",
       "1  detroitdailynew                    []   \n",
       "2       cookncooks                    []   \n",
       "3     queenofthewo  [ChristmasAftermath]   \n",
       "4     mrclydepratt                    []   \n",
       "\n",
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  islamkills are you trying to say that there we...   \n",
       "1  clinton trump should ve apologized more attack...   \n",
       "2  who was is the best president of the past year...   \n",
       "3  i don t have to guess your religion christmasa...   \n",
       "4  pence and his lawyers decided which of his off...   \n",
       "\n",
       "                                    cleaned_hashtags  \n",
       "0  islam kills are you trying to say that there w...  \n",
       "1  clinton trump should ve apologized more attack...  \n",
       "2  who was is the best president of the past year...  \n",
       "3  i don t have to guess your religion christmas ...  \n",
       "4  pence and his lawyers decided which of his off...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Unwanted Words\n",
    "\n",
    "- unique German\n",
    "- stop words\n",
    "- other weird words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniquely German Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:29.735256Z",
     "start_time": "2020-10-31T19:03:29.605405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236736, list)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of all english words known to nltk\n",
    "english_words = list(nltk.corpus.words.words())\n",
    "english_words = [word.lower() for word in english_words]\n",
    "len(english_words), type(english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:30.955860Z",
     "start_time": "2020-10-31T19:03:29.736917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147306, list)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_net = list(nltk.corpus.wordnet.words())\n",
    "word_net = [word.lower() for word in word_net]\n",
    "len(word_net), type(word_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.031353Z",
     "start_time": "2020-10-31T19:03:30.957471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323592, set)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "many_english_words = set(english_words + word_net)\n",
    "len(many_english_words), type(many_english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.549096Z",
     "start_time": "2020-10-31T19:03:31.032888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556226, list)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus.europarl_raw import german\n",
    "\n",
    "german = list(german.words())\n",
    "german = [word.lower() for word in german]\n",
    "len(german), type(german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might as well add these German stop words to my German list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.556187Z",
     "start_time": "2020-10-31T19:03:31.550573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, list)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_stop_words = stopwords.words(\"german\")\n",
    "len(german_stop_words), type(german_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.609732Z",
     "start_time": "2020-10-31T19:03:31.557472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29839"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_words = set(german + german_stop_words)\n",
    "len(german_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.721176Z",
     "start_time": "2020-10-31T19:03:31.614930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28154"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_german = set([word for word in german if word not in many_english_words])\n",
    "len(unique_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.732390Z",
     "start_time": "2020-10-31T19:03:31.725201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179, list)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_stop_words = stopwords.words(\"english\")\n",
    "print(standard_stop_words)\n",
    "len(standard_stop_words), type(standard_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.738135Z",
     "start_time": "2020-10-31T19:03:31.734059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "623"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data_files/twitter_stopwords.txt') as f:\n",
    "    words = f.read().split(',')\n",
    "    twitter_stopwords = list(words)\n",
    "    twitter_stopwords = [word.lower() for word in twitter_stopwords]\n",
    "\n",
    "len(twitter_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other words that have popped up in preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.741731Z",
     "start_time": "2020-10-31T19:03:31.739671Z"
    }
   },
   "outputs": [],
   "source": [
    "other_stops = ['amp', '…']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.745362Z",
     "start_time": "2020-10-31T19:03:31.743225Z"
    }
   },
   "outputs": [],
   "source": [
    "english_stops = set(standard_stop_words + twitter_stopwords + other_stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Word Removal Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.752914Z",
     "start_time": "2020-10-31T19:03:31.746680Z"
    }
   },
   "outputs": [],
   "source": [
    "words_to_remove = set(list(unique_german) + list(english_stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:31.757549Z",
     "start_time": "2020-10-31T19:03:31.754495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28766, set)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_remove), type(words_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:32.375947Z",
     "start_time": "2020-10-31T19:03:31.759142Z"
    }
   },
   "outputs": [],
   "source": [
    "# keep ner, entity_linker\n",
    "disabled_components = ['parser', 'tagger']\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=disabled_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:32.379609Z",
     "start_time": "2020-10-31T19:03:32.377343Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:32.382865Z",
     "start_time": "2020-10-31T19:03:32.380892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ner', 'sentencizer']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:32.386571Z",
     "start_time": "2020-10-31T19:03:32.384157Z"
    }
   },
   "outputs": [],
   "source": [
    "# as much as it pains me...\n",
    "def get_me_mike_pence(text):\n",
    "    return text.replace(\"penny\", \"pence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:32.391558Z",
     "start_time": "2020-10-31T19:03:32.388104Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_pipe(doc):\n",
    "    lemma_list = [str(tok.lemma_) for tok in doc\n",
    "                 if tok.is_alpha and tok.text not in words_to_remove]\n",
    "    lem_string = \" \".join(lemma_list)\n",
    "    # get back mike pence\n",
    "    lem_string = get_me_mike_pence(lem_string)\n",
    "    return lem_string\n",
    "\n",
    "def preprocess_pipe(texts, batch_size=100):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=batch_size):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:03:32.401608Z",
     "start_time": "2020-10-31T19:03:32.392922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_key</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>cleaned_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ryanmaxwell_1</td>\n",
       "      <td>[IslamKills]</td>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islamkills are you trying to say that there we...</td>\n",
       "      <td>islam kills are you trying to say that there w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detroitdailynew</td>\n",
       "      <td>[]</td>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookncooks</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queenofthewo</td>\n",
       "      <td>[ChristmasAftermath]</td>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmasa...</td>\n",
       "      <td>i don t have to guess your religion christmas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mrclydepratt</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_key              hashtags  \\\n",
       "0    ryanmaxwell_1          [IslamKills]   \n",
       "1  detroitdailynew                    []   \n",
       "2       cookncooks                    []   \n",
       "3     queenofthewo  [ChristmasAftermath]   \n",
       "4     mrclydepratt                    []   \n",
       "\n",
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  islamkills are you trying to say that there we...   \n",
       "1  clinton trump should ve apologized more attack...   \n",
       "2  who was is the best president of the past year...   \n",
       "3  i don t have to guess your religion christmasa...   \n",
       "4  pence and his lawyers decided which of his off...   \n",
       "\n",
       "                                    cleaned_hashtags  \n",
       "0  islam kills are you trying to say that there w...  \n",
       "1  clinton trump should ve apologized more attack...  \n",
       "2  who was is the best president of the past year...  \n",
       "3  i don t have to guess your religion christmas ...  \n",
       "4  pence and his lawyers decided which of his off...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:21.044914Z",
     "start_time": "2020-10-31T19:03:32.403080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 17.5 s, total: 1min 48s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets['processed'] = preprocess_pipe(tweets['cleaned_hashtags'], batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:21.056591Z",
     "start_time": "2020-10-31T19:05:21.046822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_key</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>cleaned_hashtags</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ryanmaxwell_1</td>\n",
       "      <td>[IslamKills]</td>\n",
       "      <td>#IslamKills Are you trying to say that there w...</td>\n",
       "      <td>islamkills are you trying to say that there we...</td>\n",
       "      <td>islam kills are you trying to say that there w...</td>\n",
       "      <td>islam kill try say terrorist attack europe ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detroitdailynew</td>\n",
       "      <td>[]</td>\n",
       "      <td>Clinton: Trump should’ve apologized more, atta...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "      <td>clinton trump should ve apologized more attack...</td>\n",
       "      <td>clinton trump apologize attack little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookncooks</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @ltapoll: Who was/is the best president of ...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "      <td>who was is the best president of the past year...</td>\n",
       "      <td>well president past retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queenofthewo</td>\n",
       "      <td>[ChristmasAftermath]</td>\n",
       "      <td>RT @jww372: I don't have to guess your religio...</td>\n",
       "      <td>i don t have to guess your religion christmasa...</td>\n",
       "      <td>i don t have to guess your religion christmas ...</td>\n",
       "      <td>guess religion christmas aftermath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mrclydepratt</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @Shareblue: Pence and his lawyers decided w...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "      <td>pence and his lawyers decided which of his off...</td>\n",
       "      <td>pence lawyer decide official email public can see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_key              hashtags  \\\n",
       "0    ryanmaxwell_1          [IslamKills]   \n",
       "1  detroitdailynew                    []   \n",
       "2       cookncooks                    []   \n",
       "3     queenofthewo  [ChristmasAftermath]   \n",
       "4     mrclydepratt                    []   \n",
       "\n",
       "                                                text  \\\n",
       "0  #IslamKills Are you trying to say that there w...   \n",
       "1  Clinton: Trump should’ve apologized more, atta...   \n",
       "2  RT @ltapoll: Who was/is the best president of ...   \n",
       "3  RT @jww372: I don't have to guess your religio...   \n",
       "4  RT @Shareblue: Pence and his lawyers decided w...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  islamkills are you trying to say that there we...   \n",
       "1  clinton trump should ve apologized more attack...   \n",
       "2  who was is the best president of the past year...   \n",
       "3  i don t have to guess your religion christmasa...   \n",
       "4  pence and his lawyers decided which of his off...   \n",
       "\n",
       "                                    cleaned_hashtags  \\\n",
       "0  islam kills are you trying to say that there w...   \n",
       "1  clinton trump should ve apologized more attack...   \n",
       "2  who was is the best president of the past year...   \n",
       "3  i don t have to guess your religion christmas ...   \n",
       "4  pence and his lawyers decided which of his off...   \n",
       "\n",
       "                                           processed  \n",
       "0  islam kill try say terrorist attack europe ref...  \n",
       "1              clinton trump apologize attack little  \n",
       "2                        well president past retweet  \n",
       "3                 guess religion christmas aftermath  \n",
       "4  pence lawyer decide official email public can see  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:21.393259Z",
     "start_time": "2020-10-31T19:05:21.058175Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data_files/tweets.pickle', 'wb') as to_write:\n",
    "   pickle.dump(tweets, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:27.068696Z",
     "start_time": "2020-10-31T19:05:21.395716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>aa</th>\n",
       "      <th>...</th>\n",
       "      <th>zynalturist</th>\n",
       "      <th>zynischen</th>\n",
       "      <th>zyoritv</th>\n",
       "      <th>zzcrane</th>\n",
       "      <th>zzion</th>\n",
       "      <th>zzjwmc</th>\n",
       "      <th>zzzs</th>\n",
       "      <th>zzzzzz</th>\n",
       "      <th>zzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203477</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203478</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203479</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203480</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203482 rows × 78004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        10  100  1000  12  13  14  16  19  20  aa  ...  zynalturist  \\\n",
       "0        0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "1        0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "2        0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "3        0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "4        0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "...     ..  ...   ...  ..  ..  ..  ..  ..  ..  ..  ...          ...   \n",
       "203477   0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "203478   0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "203479   0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "203480   0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "203481   0    0     0   0   0   0   0   0   0   0  ...            0   \n",
       "\n",
       "        zynischen  zyoritv  zzcrane  zzion  zzjwmc  zzzs  zzzzzz  zzzzzzz  \\\n",
       "0               0        0        0      0       0     0       0        0   \n",
       "1               0        0        0      0       0     0       0        0   \n",
       "2               0        0        0      0       0     0       0        0   \n",
       "3               0        0        0      0       0     0       0        0   \n",
       "4               0        0        0      0       0     0       0        0   \n",
       "...           ...      ...      ...    ...     ...   ...     ...      ...   \n",
       "203477          0        0        0      0       0     0       0        0   \n",
       "203478          0        0        0      0       0     0       0        0   \n",
       "203479          0        0        0      0       0     0       0        0   \n",
       "203480          0        0        0      0       0     0       0        0   \n",
       "203481          0        0        0      0       0     0       0        0   \n",
       "\n",
       "        zzzzzzzzzzzzzzzzz  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "...                   ...  \n",
       "203477                  0  \n",
       "203478                  0  \n",
       "203479                  0  \n",
       "203480                  0  \n",
       "203481                  0  \n",
       "\n",
       "[203482 rows x 78004 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "doc_word = cv.fit_transform(tweets['processed'])\n",
    "vect = pd.DataFrame(doc_word.toarray(),columns=cv.get_feature_names())\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:27.077032Z",
     "start_time": "2020-10-31T19:05:27.071640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaannnnnnnnnnnnnnnnnnnnnnnnnnnnnnndddddddddddddddddddddddddddddddddd',\n",
       "       'aaaaaaaaaaaaaaaaaaaaannnnnnnnnnnnnnnnnnnnddddddddddddddddddddddddddddddd',\n",
       "       'aaaaaaaaannnnnnnnnnnddddddddddddd', 'aaaaaaaaassssss', 'aaaaaand',\n",
       "       'aaaaaayyyuuuummmmmm', 'aaaaand', 'aaaand', 'aaaargh', 'aaaarrggh',\n",
       "       'aaah'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.columns[11:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:27.085066Z",
     "start_time": "2020-10-31T19:05:27.079813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['zushaelinson', 'zust', 'zuwachs', 'zuwanderer', 'zuzu', 'zuzuceo',\n",
       "       'zvezdanews', 'zvjezdanpatz', 'zw', 'zwangsfinanzierte', 'zwangsr',\n",
       "       'zweifach', 'zweifaktor', 'zweij', 'zweitwichtigstes', 'zwilling',\n",
       "       'zwillingen', 'zwischendurch', 'zwischenstationen', 'zyka',\n",
       "       'zynalturist', 'zynischen', 'zyoritv', 'zzcrane', 'zzion', 'zzjwmc',\n",
       "       'zzzs', 'zzzzzz', 'zzzzzzz', 'zzzzzzzzzzzzzzzzz'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.columns[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:27.091384Z",
     "start_time": "2020-10-31T19:05:27.087500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16805"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_cols = 94809\n",
    "start_cols - len(vect.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:27.097427Z",
     "start_time": "2020-10-31T19:05:27.093551Z"
    }
   },
   "outputs": [],
   "source": [
    "# top words in processed that are NOT in many_english_words\n",
    "def word_freq(text, num_words=10, freq_thresh=1000):\n",
    "    all_words = []\n",
    "    for tweet in list(text):\n",
    "        words = tweet.split()\n",
    "        for word in words:\n",
    "            if word not in many_english_words:\n",
    "                all_words.append(word.lower())\n",
    "    \n",
    "    top_words = Counter(all_words).most_common(num_words)\n",
    "    \n",
    "    results_list = []\n",
    "    for pair in top_words:\n",
    "        if pair[1] > freq_thresh:\n",
    "            results_list.append(pair)\n",
    "            \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:06:06.679642Z",
     "start_time": "2020-10-31T19:06:06.286369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('obama', 9788),\n",
       " ('tcot', 3945),\n",
       " ('pjnet', 2858),\n",
       " ('\\ufeff1', 2388),\n",
       " ('potus', 2120),\n",
       " ('merkel', 2092),\n",
       " ('cruz', 1910),\n",
       " ('gt', 1657),\n",
       " ('ccot', 1608),\n",
       " ('cnn', 1547)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq(tweets['processed'], num_words=10, freq_thresh=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:27.576384Z",
     "start_time": "2020-10-31T19:05:27.574648Z"
    }
   },
   "outputs": [],
   "source": [
    "# test = tweets.loc[0:50, ['text', 'clean', 'processed']]\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:27.580335Z",
     "start_time": "2020-10-31T19:05:27.578425Z"
    }
   },
   "outputs": [],
   "source": [
    "# test['replaced'] = test['processed'].replace(hashtag_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T19:05:27.583546Z",
     "start_time": "2020-10-31T19:05:27.581879Z"
    }
   },
   "outputs": [],
   "source": [
    "# test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
